name,ring,quadrant,isNew,description
Data Mesh,Assess,Techniques,FALSE,"<p>We keep getting good feedback from teams <strong>applying product management to internal platforms</strong>. One key feature to remember, though: It's not just about team structure or renaming existing platform teams; it’s also about applying product-centric working practices within the team. Specifically, we've received feedback that teams face challenges with this technique unless they have a product-centric mindset. This likely means additional roles, such as a product manager, alongside changes to other areas, such as requirements gathering and the measurement of success. Working this way means establishing empathy with internal consumers (the development teams) and collaborating with them on the design. Platform product managers create roadmaps and ensure the platform delivers value to the business and enhances the developer experience. We continue to see this technique as key to building internal platforms to roll out new digital solutions quickly and efficiently.</p>"
CI/CD infrastructure as a service,Adopt,Techniques,TRUE,"<p>The options for <strong>CI/CD infrastructure as a service</strong> have become so manifold and mature that the cases in which it's worth managing your entire CI infrastructure yourself are becoming very rare. Using managed services like <a href=""/radar/platforms/github-actions"">GitHub Actions</a>, <a href=""/radar/platforms/azure-devops"">Azure DevOps</a> or <a href=""/radar/platforms/gitlab-ci-cd"">Gitlab CI/CD</a> comes with all the common advantages (and trade-offs) of managed cloud services. You don't have to spend time, effort and hardware costs on maintenance and operations of this often complex infrastructure. Teams can take advantage of elasticity and self-service, whereas provisioning more of the right agents or getting a new plugin or feature are often a bottleneck in companies that host CI themselves. Even the use cases that require to run build and verification on your own hardware can now mostly be covered with self-hosted runners (we've written about some for GitHub Actions, <a href=""/radar/platforms/actions-runner-controller"">actions-runner-controller</a> and the <a href=""/radar/tools/philips-s-self-hosted-github-runner"">Philips's self-hosted GitHub runner</a>). Note, however, that you won’t get out-of-the-box security just because you are using a managed services; while mature services provide all the security features you need, you'll still need to use them to implement <a href=""/radar/techniques/zero-trust-security-for-ci-cd"">zero trust security for your CI/CD</a> infrastructure.</p>"
Retrospectives,Trial,Techniques,FALSE,"<p>Starter kits and templates are widely used in software projects to speed up initial setup, but they can pull in many unnecessary dependencies for a particular project. It's important to practice <strong>dependency pruning</strong> — periodically taking a hard look at these dependencies and pruning any that are not used. This helps reduce build and deploy times and decrease the project's attack surface by removing potential vulnerabilities. Although this isn't a new technique, given the increasing frequency of attacks on software supply chains, we advocate for renewed attention to it.</p>"
Strategy Roadmap and Future Planning,Trial,Techniques,FALSE,"<p>Automatically estimating, tracking and predicting cloud infrastructure run cost is crucial for today's organizations. The cloud providers' savvy pricing models, combined with the proliferation of pricing parameters and the dynamic nature of today's architecture, can lead to surprisingly expensive run costs. Even though this technique has been in Adopt since 2019, we want to highlight the importance of considering <strong>run cost as an architecture fitness function</strong>, especially today, due to accelerated cloud adoption and the growing attention to FinOps practices. Many commercial platforms provide tools that can consolidate and clarify cloud costs for business leaders. Some of them are designed to show cloud run costs to finance organizations or originating business units. </p>

<p>However, cloud consumption decisions are usually made at the engineering level, where systems are designed. It's important that the engineers making design decisions have some way of predicting the cost impact of their architectural decisions. Some teams automate this prediction early in the development lifecycle. Tools like <a href=""/radar/tools/infracost"">Infracost</a> help teams predict cost impact when thinking about possible changes to infrastructure as code. This computation can be automated and woven into the CD pipeline. Note that cost will be impacted by architectural decisions combined with actual usage levels; to do this properly, you need good projections of expected usage levels. Early and frequent feedback on run cost can prevent it from soaring. When the predicted cost deviates from what was expected or acceptable, the team can discuss whether it's time to evolve the architecture.</p>"
Source/Version Control,Trial,Techniques,TRUE,"<p>The earlier accessibility is considered in software delivery, the easier and cheaper it is to ensure what's built works for as many people as possible. Tools that help communicate <strong>accessibility annotations in designs</strong> help teams consider important elements like document structure, semantic HTML and alternative texts from the beginning of their work. This enables them to ensure user interfaces meet global accessibility standards and address common failures that are actually fairly easy to avoid. <a href=""/radar/tools/figma"">Figma</a> offers a range of accessibility notation plugins: <a href=""https://www.figma.com/community/file/953682768192596304"">The A11y Annotation Kit</a>, Twitter's <a href=""https://www.figma.com/community/file/976946194228458698"">Accessibility Annotation Library</a> and the Axe toolset's <a href=""https://www.figma.com/community/plugin/1085612091163821851/Axe-for-Designers-(FREE)"">Axe for Designers</a>.</p>"
Azure Cosmos,Adopt,Platforms,FALSE,"<p>Headless content management systems have become a common component of digital platforms. <strong><a href=""http://www.contentful.com/"">Contentful</a></strong> is still our default choice in this space, but new entrants like <a href=""/radar/platforms/strapi"">Strapi</a> have impressed us too. We particularly like Contentful's API-first approach and implementation of <a href=""http://www.contentful.com/r/knowledgebase/cms-as-code/"">CMS as code</a>. It supports powerful content modeling primitives as code and content model evolution scripts, which allow it to be treated like other data store schemas and enable <a href=""http://martinfowler.com/articles/evodb.html"">evolutionary database design</a> practices to be applied to CMS development. Recently, Contentful has released an <a href=""https://www.contentful.com/developers/docs/extensibility/app-framework/"">app framework</a> to write apps that make it easier to adapt Contentful to individual business processes and to integrate with other services. Apps can be built by and for a specific organization but a marketplace for apps is emerging, too.</p>"
Meraki,Adopt,Platforms,FALSE,"<p>Headless content management systems have become a common component of digital platforms. <strong><a href=""http://www.contentful.com/"">Contentful</a></strong> is still our default choice in this space, but new entrants like <a href=""/radar/platforms/strapi"">Strapi</a> have impressed us too. We particularly like Contentful's API-first approach and implementation of <a href=""http://www.contentful.com/r/knowledgebase/cms-as-code/"">CMS as code</a>. It supports powerful content modeling primitives as code and content model evolution scripts, which allow it to be treated like other data store schemas and enable <a href=""http://martinfowler.com/articles/evodb.html"">evolutionary database design</a> practices to be applied to CMS development. Recently, Contentful has released an <a href=""https://www.contentful.com/developers/docs/extensibility/app-framework/"">app framework</a> to write apps that make it easier to adapt Contentful to individual business processes and to integrate with other services. Apps can be built by and for a specific organization but a marketplace for apps is emerging, too.</p>"
GitHub,Trail,Platforms,FALSE,"<p><strong><a href=""https://docs.github.com/en/actions"">GitHub Actions</a></strong> has become a default starting point for many teams that need to get CI or CD up and running quickly in a greenfield environment. Among other things, it can take on more complex workflows and call other actions in composite actions. Although the ecosystem in <a href=""https://github.com/marketplace?type=actions"">GitHub Marketplace</a> continues to grow, we still urge caution in giving third-party GitHub Actions access to your build pipeline. We recommend following GitHub's advice on <a href=""https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions"">security hardening</a> to avoid sharing secrets in insecure ways. However, the convenience of creating your build workflow directly in GitHub next to your source code combined with the ability to run GitHub Actions locally, using open-source tools such as <a href=""https://github.com/nektos/act"">act</a>, is a compelling option that has streamlined the setup and onboarding of our teams.</p>"
Leankit,Adopt,Tools,FALSE,"<p><strong><a href=""https://dvc.org/"">DVC</a></strong> continues to be our tool of choice for managing experiments in data science projects. The fact that it's <a href=""/radar/tools/git"">Git</a>-based makes it a known turf for developers to bring engineering practices to the data science ecosystem. DVC's opinionated view of a model checkpoint carefully encapsulates a training data set, a test data set, model hyperparameters and the code. By making <a href=""/radar/techniques/versioning-data-for-reproducible-analytics"">reproducibility</a> a first-class concern, it allows the team to time travel across various versions of the model. Our teams have successfully used DVC in production to enable <a href=""/radar/techniques/continuous-delivery-for-machine-learning-cd4ml"">continuous delivery for ML (CD4ML)</a>; it can be plugged in with any type of storage (including AWS S3, Google Cloud Storage, <a href=""/radar/platforms/minio"">MinIO</a> and Google Drive). However, with data sets getting bigger, file system–based snapshotting could become particularly expensive. When the underlying data is changing rapidly, DVC on top of a good versioned storage allows tracking model drifts over a period of time. Our teams have effectively used DVC on top of data storage formats like <a href=""/radar/platforms/delta-lake"">Delta Lake</a> which optimizes versioning (<a href=""https://en.wikipedia.org/wiki/Copy-on-write"">COW</a>). A majority of our data science teams set up DVC as a day zero task while they bootstrap a project; for this reason we're happy to move it to Adopt.</p>"
InVision,Trial,Tools,TRUE,"<p>As more organizations adopt cloud computing, many are starting to integrate multiple cloud providers simultaneously to maximize flexibility and minimize vendor lock-in. However, managing keys and access controls across multiple cloud providers can be a significant challenge, leading to increased complexity and security risks. <strong><a href=""https://www.akeyless.io/"">Akeyless</a></strong> is a centralized, cloud-based platform that provides unified secrets management with a range of advantages for managing secrets and sensitive data. It integrates seamlessly with different providers, simplifying the management of secrets and access controls to monitor and control who has access to sensitive data; with encryption, access controls, multi-factor authentication and other security mechanisms it ensures only authorized users are able to access sensitive data. Additionally, it provides an intuitive interface for administration and monitoring, providing a less complex and more scalable developer and administration experience.</p>"
Miro/Mural,On Hold,Tools,TRUE,"<p>Within any organization, API producers and consumers need to stay in sync about the schemas that will be used for communication among them. Especially as the number of APIs and related producers and consumers grow in the organization, what may start with simply passing around schemas among teams will start to hit scaling challenges. Faced with this issue, some of our teams have turned to <strong><a href=""https://www.apicur.io/registry/"">Apicurio Registry</a></strong>, an open-source, centralized registry for various types of schemas and API artifacts, including OpenAPI specifications and Protobuf and Avro schemas. Apicurio Registry allows users to interact with it through a UI as well as a REST API and a Maven plugin. It also has the option to enforce schema evolution restrictions, such as backward compatibility. Moreover, when it comes to working with <a href=""/radar/platforms/apache-kafka"">Kafka</a> clients, Apicurio Registry is compatible with Confluent Schema Registry. While our teams have found Confluent Schema Registry's documentation more helpful, Apicurio Registry meets their needs for a source of truth for various schemas.</p>"
Python,Trial,languages-and-frameworks,FALSE,"<p>Our teams now view <strong>Gradle Kotlin DSL</strong> as the default for starting new projects using <a href=""/radar/tools/gradle"">Gradle</a>, preferring it over <a href=""/radar/languages-and-frameworks/groovy"">Groovy</a>. Teams already using Groovy should consider migration. <a href=""/radar/languages-and-frameworks/kotlin"">Kotlin</a> provides better support for refactoring and simpler editing in IDEs, and our teams report that it produces code that is easier to read and maintain. Given some IDEs now support migration, it should be relatively quick to experiment with replacing existing Groovy. In some situations Kotlin might be slower than Groovy; however, for many projects, this is unlikely to impact the team.</p>"
Svelte,Trial,languages-and-frameworks,FALSE,"<p><strong><a href=""https://pytorch.org/"">PyTorch</a></strong> continues to be our choice of machine learning (ML) framework. Most of our teams prefer PyTorch over <a href=""/radar/languages-and-frameworks/tensorflow"">TensorFlow</a>. PyTorch exposes the inner workings of ML that TensorFlow hides, making it easier to debug. With dynamic computational graphs, model optimization is much easier compared to any other ML framework. The extensive availability of <a href=""https://huggingface.co/models"">State-of-the-Art (SOTA) models</a> and the ease of implementing research papers make PyTorch stand out. When it comes to graph ML, <a href=""https://pytorch-geometric.readthedocs.io/en/latest/"">PyTorch Geometric</a> is a more mature ecosystem and our teams have had great experiences with it. PyTorch has also gradually bridged gaps when it comes to model deployment and scaling; our teams have used <a href=""https://github.com/pytorch/serve"">TorchServe</a> to serve pretrained models successfully in production, for example. With many teams defaulting to PyTorch for their end-to-end deep-learning needs, we happily recommend adopting PyTorch.</p>"
